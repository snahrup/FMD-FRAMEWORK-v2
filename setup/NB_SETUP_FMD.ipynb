{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6a663d-0e92-4d07-99e6-365c48b9c726",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "![FMD_Overview](https://github.com/edkreuk/FMD_FRAMEWORK/blob/main/Images/FMD_Overview.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f028883-3c89-4adf-8da2-9a1d7f5b979d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install ms-fabric-cli pillow cairosvg --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed7375-2e5f-4b5a-ae9f-672b337ddd94",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Configuration and Parameters\n",
    "\n",
    "**Fabric Administrator Role is required to create domain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf0bf0-89ce-4eb9-bdc3-8efd8444ea4c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "assign_icons = True                                 # Set to True to assign default icons to workspaces; set to False if you have already assigned custom icons\n",
    "load_demo_data= True                                # Set to True if you want to load the demo data, otherwise set to False\n",
    "lakehouse_schema_enabled = True                     # Set to True if you want to use the lakehouse schema, otherwise set to False\n",
    "\n",
    "driver = '{ODBC Driver 18 for SQL Server}'          # Change this if you use a different driver\n",
    "overwrite_variable_library=True                     # By default the Library is overwritten, change this to \"False\" if you have custom changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e5d8d-7471-4d92-8385-9cc5ae81a47b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## KeyVault settings\n",
    "For future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086f732-b219-4101-9eab-92c95044c075",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "key_vault_uri_name='val_key_vault_uri_name'\n",
    "key_vault_tenant_id='val_key_vault_tenant_id'\n",
    "key_vault_client_id='val_key_vault_client_id'\n",
    "key_vault_client_secret='val_key_vault_client_secret'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9cdee-13a8-4154-a7ce-6b13aec0d244",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Capacity configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6095d96-c13d-49fd-b388-7347598d2032",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "reassign_capacity= True                                   # If set to False existing assigned capacities to workspaces will no be overwritten\n",
    "\n",
    "capacity_name_dvlm = 'Trial-20260127T191700Z-WTXWXnRGvEeDO4sEgXlcCw'   # IP Corp Fabric Trial capacity\n",
    "capacity_name_prod = 'Trial-20260127T191700Z-WTXWXnRGvEeDO4sEgXlcCw'    # Same trial capacity for prod\n",
    "capacity_name_config = 'Trial-20260127T191700Z-WTXWXnRGvEeDO4sEgXlcCw'  # Same trial capacity for config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4aa59-bbe8-4937-a983-8ddf5859760e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Domain and Framework settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6f777-a65a-491b-ba14-0ce8b19c04ff",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "framework_post_fix= ''                              # post fix to be added at the end of workspace for example INTEGRATION FMD\n",
    "if framework_post_fix != '':\n",
    "   framework_post_fix= ' '+ framework_post_fix      #If empty leave as is else add a space before for better visibility\n",
    "\n",
    "##Domains\n",
    "create_domains=  False                              # IP Corp - skipping domain creation\n",
    "\n",
    "domain_name='INTEGRATION'                           # Main Domain for Integration\n",
    "\n",
    "domain_contributor_role = {\"type\": \"Contributors\",\"principals\": [{\"id\": \"91741faf-f475-4266-95da-abc62bd69de6\",\"type\": \"ServicePrincipal\"}, {\"id\": \"7d0cbeea-36ee-48a5-8c67-ca8183f8b0bd\",\"type\": \"Group\"}  ]}  # IP Corp Fabric-PowerBI-API SP + Fabric Admins group\n",
    "\n",
    "##Connections\n",
    "connection_fabric_datapipelines_name='CON_FMD_FABRIC_PIPELINES'\n",
    "connection_fabric_notebooks_name='CON_FMD_FABRIC_NOTEBOOKS'\n",
    "connection_fabric_database_name='CON_FMD_FABRIC_SQL'\n",
    "connection_fabric_adf_name='CON_FMD_ADF_PIPELINES'\n",
    "\n",
    "connection_role =  {\"role\": \"owner\",\"principals\": [{\"id\": \"91741faf-f475-4266-95da-abc62bd69de6\",\"type\": \"ServicePrincipal\"}, {\"id\": \"7d0cbeea-36ee-48a5-8c67-ca8183f8b0bd\",\"type\": \"Group\"}  ]}  # IP Corp Fabric-PowerBI-API SP + Fabric Admins group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ce033-5b29-4c7a-9b6f-03854ddf933c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e67871-6536-43c0-ac2e-21ff8571d022",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Repo Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3945911-68db-4961-99db-5020ac37e1b7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#FMD Framework code\n",
    "##### DO NOT CHANGE UNLESS SPECIFIED OTHERWISE ####\n",
    "repo_owner = \"edkreuk\"              # Owner of the repository\n",
    "repo_name = \"FMD_FRAMEWORK\"         # Name of the repository\n",
    "branch = \"main\"                     #\"main\" is default                    \n",
    "folder_prefix = \"\"\n",
    "###################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443c89a-6aec-46c1-9456-37e8f4ab93aa",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Workspace Roles Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab87f1-553e-426f-9c42-1f2232cd5e8f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "workspace_roles_code = [ # IP Corp: Service Principal + Fabric Admins group\n",
    "                        {\n",
    "                       \"principal\": {\n",
    "                            \"id\": '91741faf-f475-4266-95da-abc62bd69de6',\n",
    "                            \"type\": \"ServicePrincipal\"\n",
    "                        },\n",
    "                        \"role\": \"contributor\"  #(choose from 'admin', 'member', 'contributor', 'viewer')\n",
    "                        },\n",
    "                        {\n",
    "                       \"principal\": {\n",
    "                            \"id\": '7d0cbeea-36ee-48a5-8c67-ca8183f8b0bd',\n",
    "                            \"type\": \"Group\"\n",
    "                        },\n",
    "                        \"role\": \"admin\"\n",
    "                        }\n",
    "                    ]\n",
    "workspace_roles_data =  [ # IP Corp: Service Principal + Fabric Admins group\n",
    "                        {\n",
    "                       \"principal\": {\n",
    "                            \"id\": '91741faf-f475-4266-95da-abc62bd69de6',\n",
    "                            \"type\": \"ServicePrincipal\"\n",
    "                        },\n",
    "                        \"role\": \"contributor\"  #(choose from 'admin', 'member', 'contributor', 'viewer')\n",
    "                        },\n",
    "                        {\n",
    "                       \"principal\": {\n",
    "                            \"id\": '7d0cbeea-36ee-48a5-8c67-ca8183f8b0bd',\n",
    "                            \"type\": \"Group\"\n",
    "                        },\n",
    "                        \"role\": \"admin\"\n",
    "                        }\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b09b0-c276-47f6-b223-57220f6af1c3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Workspace configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada47fa-6823-4cdc-bebe-3f573f4f2bd1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "##### DO NOT CHANGE UNLESS SPECIFIED OTHERWISE, FE ADDING NEW ENVIRONMENTS ####\n",
    "environments = [\n",
    "                    {\n",
    "                        'environment_name' : 'development',                                     # Name of target environment\n",
    "                        'workspaces': {\n",
    "                            'data' : {\n",
    "                                'name' : domain_name + ' DATA (D)' +  framework_post_fix,       # Name of target code workspace for development\n",
    "                                'roles' : workspace_roles_data,                                 # Roles to assign to the workspace\n",
    "                                'capacity_name' : capacity_name_dvlm                            # Name of target data workspace for development\n",
    "                            },\n",
    "                            'code' : {\n",
    "                                'name' : domain_name + ' CODE (D)' +  framework_post_fix,       # Name of target data workspace for development\n",
    "                                'roles' : workspace_roles_code,                                 # Roles to assign to the workspace\n",
    "                                'capacity_name' : capacity_name_dvlm                            # Name of target code workspace for development\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        'environment_name' : 'production',                                      # Name of target environment\n",
    "                        'workspaces': {\n",
    "                            'data' : {\n",
    "                                'name' : domain_name + ' DATA (P)' +  framework_post_fix,       # Name of target data workspace for production\n",
    "                                'roles' : workspace_roles_data,                                 # Roles to assign to the workspace\n",
    "                                'capacity_name' : capacity_name_prod                            # Name of target data workspace for production   \n",
    "                            },\n",
    "                            'code' : {\n",
    "                                'name' : domain_name + ' CODE (P)' +  framework_post_fix,       # Name of target code workspace for production\n",
    "                                'roles' : workspace_roles_code,                                 # Roles to assign to the workspace\n",
    "                                'capacity_name' : capacity_name_prod                            # Name of target code workspace for production\n",
    "                            }                           \n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd9c8a-c6e7-40b4-84e1-c33c0ca10667",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Fabric Database Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebe458-bd01-495a-81a1-6b7b5aef9ec8",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "configuration = {\n",
    "                    'workspace': {\n",
    "                        'name' : domain_name + ' CONFIG' +  framework_post_fix,             # Name of target workspace\n",
    "                        'roles' : workspace_roles_data,                                     # Roles to assign to the workspace\n",
    "                        'capacity_name' : capacity_name_config                              # Name of target capacity for the configuration workspace\n",
    "                    },\n",
    "                       'DatabaseName' : 'SQL_'+domain_name+'_FRAMEWORK'                     # Name of target configuration Fabric SQL Database\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32269821-d83f-41ac-a3d4-a19f8cb555de",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Download source & config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856eaf5-444f-4090-ab29-fea24fcd9b10",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from time import sleep, time\n",
    "import json\n",
    "import nbformat\n",
    "import shutil\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "import yaml\n",
    "import struct\n",
    "import pyodbc\n",
    "import sempy.fabric as fabric\n",
    "import cairosvg\n",
    "import base64\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22cc332-d939-4def-8971-84f762931ce2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "def download_folders_as_zip(repo_owner, repo_name, output_zip, branch=\"main\", folders_to_extract=None, remove_folder_prefix=\"\"):\n",
    "    if folders_to_extract is None:\n",
    "        folders_to_extract = []\n",
    "\n",
    "    # Construct the URL for the GitHub API to download the repository as a zip file\n",
    "    url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/zipball/{branch}\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Ensure the directory for the output zip file exists\n",
    "    os.makedirs(os.path.dirname(output_zip), exist_ok=True)\n",
    "\n",
    "    # Create a zip file in memory from GitHub response\n",
    "    with zipfile.ZipFile(BytesIO(response.content)) as zipf:\n",
    "        # Open output zip in append mode\n",
    "        with zipfile.ZipFile(output_zip, 'w') as output_zipf:\n",
    "            \n",
    "            for file_info in zipf.infolist():\n",
    "                for folder in folders_to_extract:\n",
    "                    folder_path = f\"/{folder}\" if not folder.startswith(\"/\") else folder\n",
    "                    if re.sub(r'^.*?/', '/', file_info.filename).startswith(folder_path):\n",
    "                        file_data = zipf.read(file_info.filename)\n",
    "                        parts = file_info.filename.split('/')\n",
    "                        if remove_folder_prefix:\n",
    "                            parts = [p for p in parts if p != remove_folder_prefix]\n",
    "                        output_zipf.writestr('/'.join(parts[1:]), file_data)\n",
    "\n",
    "def uncompress_zip_to_folder(zip_path, extract_to):\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    os.remove(zip_path)\n",
    "\n",
    "def copy_to_tmp(name):\n",
    "    shutil.rmtree(\"./builtin/tmp\", ignore_errors=True)\n",
    "    path2zip = \"./builtin/src/src.zip\"\n",
    "\n",
    "    prefixes = [\n",
    "        f\"src/{name}\"\n",
    "    ]\n",
    "\n",
    "    with ZipFile(path2zip) as archive:\n",
    "        for prefix in prefixes:\n",
    "            matched_files = [file for file in archive.namelist() if file.startswith(prefix)]\n",
    "            if matched_files:\n",
    "                for file in matched_files:\n",
    "                    archive.extract(file, \"./builtin/tmp\")\n",
    "                return f\"./builtin/tmp/{prefix}\"  # Return only the first matching prefix\n",
    "\n",
    "    return None  # Nothing found\n",
    "\n",
    "# \u2705 Combine all folders into one zip\n",
    "download_folders_as_zip(repo_owner, repo_name, output_zip = \"./builtin/src/src.zip\", branch = branch, folders_to_extract= [f\"{folder_prefix}/src\"] , remove_folder_prefix = f\"{folder_prefix}\")\n",
    "download_folders_as_zip(repo_owner, repo_name, output_zip = \"./builtin/config/config.zip\", branch = branch, folders_to_extract= [f\"{folder_prefix}/config\"] , remove_folder_prefix = f\"{folder_prefix}\")\n",
    "# \u2705 Uncompress everything into ./builtin\n",
    "uncompress_zip_to_folder(zip_path = \"./builtin/config/config.zip\", extract_to= \"./builtin\")\n",
    "\n",
    "mapping_table=[]\n",
    "tasks=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c3526-9a63-430c-90e4-00ece0aebfa5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# CLI Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e2fa8-e10d-45a9-82a7-266feaedc4ba",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Set environment parameters for Fabric CLI\n",
    "token = notebookutils.credentials.getToken('pbi')\n",
    "os.environ['FAB_TOKEN'] = token\n",
    "os.environ['FAB_TOKEN_ONELAKE'] = token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b39ba9-62fb-421b-be07-2607f79fccdb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Deployment functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb5fa4-5bf7-408b-9630-1533ba0d031a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Load configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937feb4e-a67f-486c-ad43-0ae628b71e34",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "base_path = './builtin/'\n",
    "config_path = os.path.join(base_path, 'config/item_config.yaml')\n",
    "\n",
    "with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "deploy_order_path = os.path.join(base_path, 'config/item_deployment.json')\n",
    "with open(deploy_order_path, 'r') as file:\n",
    "        item_deployment =json.load(file)\n",
    "\n",
    "deploy_order_path = os.path.join(base_path, 'config/item_initial_setup.json')\n",
    "with open(deploy_order_path, 'r') as file:\n",
    "        item_initial_setup =json.load(file)\n",
    "\n",
    "deploy_order_path = os.path.join(base_path, 'config/data_deployment.json')\n",
    "with open(deploy_order_path, 'r') as file:\n",
    "        data_deployment =json.load(file)\n",
    "\n",
    "deploy_order_path = os.path.join(base_path, 'config/lakehouse_deployment.json')\n",
    "with open(deploy_order_path, 'r') as file:\n",
    "        lakehouse_deployment =json.load(file)\n",
    "\n",
    "deploy_icons_path = os.path.join(base_path, 'config/fabric_icons.xml')\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse(deploy_icons_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Create a dictionary to store icon name and base64\n",
    "fabric_icons_fmd = {}\n",
    "for item in root.findall('icon'):\n",
    "    name = item.find('name').text if item.find('name') is not None else \"No name\"\n",
    "    base64_str = item.find('base64').text if item.find('base64') is not None else \"\"\n",
    "    fabric_icons_fmd[name] = base64_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143250a-9c75-4f6a-9f44-78dde9852195",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a1ab7-998e-4959-86fd-8e82c0894076",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Load latest version NB_UTILITIES_SETUP_FMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccfaae6-01d5-4ae2-a1bf-9d3fca3b240b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "def run_fab_command(command, capture_output=False, silently_continue=False, raw_output=False):\n",
    "    \"\"\"\n",
    "    Executes a Fabric CLI command with optional output capture and error handling.\n",
    "    \"\"\"\n",
    "    result = subprocess.run([\"fab\", \"-c\", command], capture_output=capture_output, text=True)\n",
    "    if not silently_continue and (result.returncode > 0 or result.stderr):\n",
    "        raise Exception(f\"Error running fab command. exit_code: '{result.returncode}'; stderr: '{result}'\")\n",
    "    if capture_output:\n",
    "        return result if raw_output else result.stdout.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe7e00-f8dd-44bb-80ee-0d4e68222b10",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "workspace_id = fabric.get_workspace_id()\n",
    "result=run_fab_command(\"api -X get workspaces/\"+workspace_id, capture_output=True, silently_continue=False)\n",
    "workspace_name=json.loads(result)[\"text\"][\"displayName\"]\n",
    "\n",
    "for it in item_initial_setup:\n",
    "    name = it[\"name\"]\n",
    "    type = it[\"type\"]\n",
    "    tmp_path = copy_to_tmp(name)\n",
    "\n",
    "    cli_parameter = ''\n",
    "\n",
    "    if \"Notebook\" in name:\n",
    "        cli_parameter += \" --format .py\"\n",
    "        result = run_fab_command(f\"import {workspace_name}.Workspace/{name} -i {tmp_path} -f {cli_parameter}\",capture_output=True, silently_continue=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574aafa6-c083-421d-af19-efb70f46c59d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Load all notebook functions\n",
    "nb_str = notebookutils.notebook.getDefinition(\"NB_UTILITIES_SETUP_FMD\")\n",
    "nb = nbformat.from_dict(json.loads(nb_str))\n",
    "shell = get_ipython()\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == 'code':\n",
    "        code = ''.join(cell['source'])\n",
    "        shell.run_cell(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d9b38-da94-42a7-a561-99bc7d2d86ac",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Integration Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0bf14-919b-4092-9af8-bcb7f6d49c5a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "if create_domains:\n",
    "    create_fabric_domain(domain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ee96c7-0d2a-4d02-b47c-1dc2537df497",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e49f81-14f5-4f35-9c84-17be5f362954",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Get existing connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceacfee-03af-4972-a3c6-602c1ac204e5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Create connection and get connection id\n",
    "\n",
    "##CON_FMD_FABRIC_PIPELINES\n",
    "connection_id=create_or_get_fmd_connection(connection_fabric_datapipelines_name,connection_role, 'FabricDataPipelines')\n",
    "mapping_table.append({\"Description\": connection_fabric_datapipelines_name,\"ItemType\": \"connection\" ,\"environment\": 'config' ,\"old_id\": config[\"connections\"][\"CON_FMD_FABRIC_PIPELINES\"], \"new_id\": connection_id})\n",
    "\n",
    "##CON_FMD_FABRIC_NOTEBOOKS\n",
    "connection_id=create_or_get_fmd_connection(connection_fabric_notebooks_name,connection_role,'Notebook' )\n",
    "mapping_table.append({\"Description\": connection_fabric_notebooks_name,\"ItemType\": \"connection\" ,\"environment\": 'config' ,\"old_id\": config[\"connections\"][\"CON_FMD_FABRIC_NOTEBOOKS\"], \"new_id\": connection_id})\n",
    "\n",
    "##CON_FMD_FABRIC_SQL\n",
    "connection_id=create_or_get_fmd_connection(connection_fabric_database_name,connection_role,'FabricSql' )\n",
    "mapping_table.append({\"Description\": connection_fabric_database_name,\"ItemType\": \"connection\" ,\"environment\": 'config' ,\"old_id\": config[\"connections\"][\"CON_FMD_FABRIC_SQL\"], \"new_id\": connection_id})\n",
    "\n",
    "#CON_FMD_ADF_PIPELINES GET Connection id of ADF Connection if exist, when using different name, change below\n",
    "connection_id=create_or_get_fmd_connection(connection_fabric_adf_name,connection_role,'AzureDataFactory' )\n",
    "mapping_table.append({\"Description\": \"CON_FMD_ADF_PIPELINES\",\"ItemType\": \"connection\" ,\"environment\": 'config' ,\"old_id\": config[\"connections\"][\"CON_FMD_ADF_PIPELINES\"], \"new_id\": connection_id})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c962f96-4a74-41ad-a6e0-397622eefbf9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create workspaces(Code and Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3bd18-4ed8-4f57-b9c4-b83ca72768f9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for environment in environments:\n",
    "    print(f\"--------------------------\")\n",
    "    print(f\"Creating/Updating Workspace: {environment['environment_name']}\")\n",
    "    deploy_workspaces(domain_name,workspace=environment['workspaces']['code'], workspace_name=environment['workspaces']['code']['name'], environment_name=environment['environment_name'], old_id=config[\"workspaces\"][\"workspace_code\"], mapping_table=mapping_table, tasks=tasks)\n",
    "    deploy_workspaces(domain_name,workspace=environment['workspaces']['data'], workspace_name=environment['workspaces']['data']['name'], environment_name=environment['environment_name'], old_id=config[\"workspaces\"][\"workspace_data\"], mapping_table=mapping_table, tasks=tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b978e7-12ed-4697-a9fd-dc55a947a44e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create workspace(Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc31d7e-150e-440d-ad2d-95974b74babe",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Creating/Updating Workspace: Configuration\")\n",
    "deploy_workspaces(domain_name,workspace=configuration['workspace'], workspace_name=configuration['workspace']['name'], environment_name='config', old_id=config[\"workspaces\"][\"workspace_config\"], mapping_table=mapping_table, tasks=tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb4578-f42d-447a-9407-03cb328c1eb0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create Lakehouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47059838-9160-4c2f-aacf-44a5def589fa",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for environment in environments:\n",
    "    print(f\"\\n--------------------------\")\n",
    "    print(f\"Processing: {environment['environment_name']}\")\n",
    "    for workspace in [environment['workspaces']['data']]:\n",
    "        for it in lakehouse_deployment:\n",
    "            new_id = None\n",
    "            name = it[\"name\"]\n",
    "            type = it[\"type\"]\n",
    "            deploy_item(workspace['name'],name,mapping_table,environment['environment_name'],tasks,lakehouse_schema_enabled,it)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33263830-e547-48a7-bc11-9ece4c56d6da",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create Fabric database (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec325609-7c22-4691-b309-d0a67069712d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for deployment_item in data_deployment:\n",
    "        if deployment_item['type'] in ('SQLDatabase'):\n",
    "                name = configuration['DatabaseName']\n",
    "                type = deployment_item[\"type\"]\n",
    "                name=name+'.'+type\n",
    "                server, database_name=deploy_item(workspace_name=configuration['workspace']['name'],name=name,mapping_table=mapping_table, environment_name='config',tasks= tasks, lakehouse_schema_enabled=lakehouse_schema_enabled,it=deployment_item)\n",
    "\n",
    "##!NOTE: in Case of an error check if you're not using a trial capacitiy or the capacity you assigned is paused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efaf53a-7f5d-4136-915c-6a3dd4ea5513",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0132e36-8609-4503-a12d-43fead5890ed",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e02cb-6e4d-424a-929f-67334128dca1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for it in item_deployment:\n",
    "    if it['type'] in ('Environment'):\n",
    "        new_id = None\n",
    "        name = it[\"name\"]\n",
    "        type = it[\"type\"]\n",
    "        deploy_item(configuration['workspace']['name'],name,mapping_table,environment['environment_name'], tasks, lakehouse_schema_enabled,it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e72c5c6-d9c3-4af2-95b1-8f51eb341df5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Notebooks and VariableLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbaf8ad-721a-46c3-8c2c-1ea9a48dc1a3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for environment in environments:\n",
    "    print(f\"\\n--------------------------\")\n",
    "    print(f\"Processing: {environment['environment_name']}\")\n",
    "    for workspace in [environment['workspaces']['code']]:\n",
    "        for it in item_deployment:\n",
    "            if it['type'] in ('Notebook','VariableLibrary'):\n",
    "\n",
    "                name = it[\"name\"]\n",
    "                type = it[\"type\"]\n",
    "                deploy_item(workspace['name'],name,mapping_table,environment['environment_name'], tasks, lakehouse_schema_enabled,it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feea701-eaf7-45bc-900c-06a6219f362a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Make sure out token is still valid before we continou, sometime it can take a bit longer that's we will check it again\n",
    "token = notebookutils.credentials.getToken('pbi')\n",
    "os.environ['FAB_TOKEN'] = token\n",
    "os.environ['FAB_TOKEN_ONELAKE'] = token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c019217-d562-4339-964a-e4f13228c751",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### DataPipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296baf6d-620f-4d13-9bf9-85506b864b41",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for environment in environments:\n",
    "    print(f\"\\n--------------------------\")\n",
    "    print(f\"Processing: {environment['environment_name']}\")\n",
    "    for workspace in [environment['workspaces']['code']]:\n",
    "        exclude = []\n",
    "        for it in item_deployment:\n",
    "            if it['type'] in ('DataPipeline'):\n",
    "                new_id = None\n",
    "                name = it[\"name\"]\n",
    "                type = it[\"type\"]\n",
    "\n",
    "                if name in exclude:\n",
    "                    continue\n",
    "                deploy_item(workspace['name'],name,mapping_table,environment['environment_name'], tasks, lakehouse_schema_enabled,it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91a5c1-bd07-46b6-a88f-ba7fcb305c4f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Workspace Icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a019b-f9dc-48f5-9fad-14ca06c30193",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "if assign_icons:  \n",
    "    seen = set()\n",
    "    workspaces = []\n",
    "    # Get cluster URL for use in metadata endpoints\n",
    "    cluster_base_url = get_cluster_url()\n",
    "\n",
    "    for item in mapping_table:\n",
    "        if item['ItemType'] == 'Workspace':\n",
    "            key = (item['Description'], item['new_id'])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                workspaces.append({'displayName': item['Description'], 'id': item['new_id']})\n",
    "    fabric_icons = fabric_icons_fmd \n",
    "\n",
    "    for workspace in workspaces:\n",
    "        display_name = workspace['displayName'].lower()\n",
    "        \n",
    "        # Assign icon\n",
    "        for icon_key, icon_value in workspace_icon_def['icons'].items():\n",
    "            if icon_key in display_name:\n",
    "                workspace[\"icon\"] = icon_value\n",
    "                workspace_icon = fabric_icons.get(icon_value)\n",
    "                break\n",
    "        else:\n",
    "            workspace[\"icon\"] = None\n",
    "            workspace_icon = None\n",
    "\n",
    "        workspace[\"icon_base64img\"] = workspace_icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bdcf88-cac2-4546-8c7f-cbfdb390461e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "if assign_icons:\n",
    "    # Dry run - Display pre and post icons based on specified workspace filters and workspace icon definition. Will NOT update any icons!\n",
    "    display_workspace_icons(workspaces)\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca909ec2-916a-4400-82bc-acf434bc4550",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Deploy Workspace Icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f42d6-e74c-4909-8ac0-ab14d8f68e0e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "if assign_icons:\n",
    "    for workspace in workspaces:\n",
    "            set_workspace_icon(workspace.get('id'), workspace.get('icon_base64img'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc252ff-6f50-41f9-9c6d-165300837bb6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create SQL deployment Manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031bbb1-ae9a-4a26-8e14-e942a4fca2f8",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Add Connections to Fabric Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd478ed5-39c1-4f18-8359-b99529771086",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "result = subprocess.run([\"fab\", \"api\", \"-X\", \"get\", \"connections\"], capture_output=True, text=True)\n",
    "connections=json.loads(result.stdout)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438153da-a957-4c48-9394-3cfc7c8aa014",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "custom_sql_deployment = {\"queries_stored_procedures\": []}\n",
    "for connection in connections['value']:\n",
    "    \n",
    "    display_name = connection.get('displayName', '')\n",
    "    if display_name and display_name.startswith('CON_FMD'):\n",
    "        connection_type = connection.get('connectionDetails', {}).get('type', 'Unknown')\n",
    "        connection_id = connection.get('id')\n",
    "      \n",
    "        exec_statement = (\n",
    "            f\"EXEC [integration].[sp_UpsertConnection] \"\n",
    "            f\"@ConnectionGuid = \\\"{connection_id}\\\", \"\n",
    "            f\"@Name = \\\"{display_name}\\\", \"\n",
    "            f\"@Type = \\\"{connection_type}\\\", \"\n",
    "            f\"@IsActive = 1\"\n",
    "        )\n",
    "        custom_sql_deployment[\"queries_stored_procedures\"].append(exec_statement)\n",
    "        custom_sql_deployment[\"queries_stored_procedures\"].append(f'EXEC [integration].[sp_UpsertConnection] @ConnectionGuid = \"00000000-0000-0000-0000-000000000001\", @Name = \"CON_FMD_NOTEBOOK\", @Type = \"NOTEBOOK\", @IsActive = 1')\n",
    "        custom_sql_deployment[\"queries_stored_procedures\"].append(f'EXEC [integration].[sp_UpsertConnection] @ConnectionGuid = \"00000000-0000-0000-0000-000000000000\", @Name = \"CON_FMD_ONELAKE\", @Type = \"ONELAKE\", @IsActive = 1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209b88e-345d-4aeb-892e-bcf776ef599f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Add DataSources to Fabric Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1576485-4a56-49f1-a1b1-275a9f5d5e04",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "custom_sql_deployment[\"queries_stored_procedures\"].append(\"\"\"\n",
    "    DECLARE @DataSourceIdInternal INT = (SELECT DataSourceId FROM integration.DataSource WHERE Name = 'LH_DATA_LANDINGZONE' and Type='ONELAKE_TABLES_01')\n",
    "    DECLARE @ConnectionIdInternal INT = (SELECT ConnectionId FROM integration.Connection WHERE ConnectionGuid = '00000000-0000-0000-0000-000000000000')\n",
    "    EXECUTE [integration].[sp_UpsertDataSource] \n",
    "        @ConnectionId = @ConnectionIdInternal\n",
    "        ,@DataSourceId = @DataSourceIdInternal\n",
    "        ,@Name = 'LH_DATA_LANDINGZONE'\n",
    "        ,@Namespace = 'ONELAKE'\n",
    "        ,@Type = 'ONELAKE_TABLES_01'\n",
    "        ,@Description = 'ONELAKE_TABLES'\n",
    "        ,@IsActive = 1\n",
    "\"\"\")\n",
    "custom_sql_deployment[\"queries_stored_procedures\"].append(\"\"\"\n",
    "    DECLARE @DataSourceIdInternal INT = (SELECT DataSourceId FROM integration.DataSource WHERE Name = 'LH_DATA_LANDINGZONE' and Type ='ONELAKE_FILES_01')\n",
    "    DECLARE @ConnectionIdInternal INT = (SELECT ConnectionId FROM integration.Connection WHERE ConnectionGuid = '00000000-0000-0000-0000-000000000000')\n",
    "    EXECUTE [integration].[sp_UpsertDataSource] \n",
    "        @ConnectionId = @ConnectionIdInternal\n",
    "        ,@DataSourceId = @DataSourceIdInternal\n",
    "        ,@Name = 'LH_DATA_LANDINGZONE'\n",
    "        ,@Namespace = 'ONELAKE'\n",
    "        ,@Type = 'ONELAKE_FILES_01'\n",
    "        ,@Description = 'ONELAKE_FILES'\n",
    "        ,@IsActive = 1\n",
    "\"\"\")\n",
    "custom_sql_deployment[\"queries_stored_procedures\"].append(\"\"\"\n",
    "        DECLARE @DataSourceIdInternal INT = (SELECT DataSourceId FROM integration.DataSource WHERE Name = 'CUSTOM_NOTEBOOK' and Type='NOTEBOOK')\n",
    "        DECLARE @ConnectionIdInternal INT = (SELECT ConnectionId FROM integration.Connection WHERE ConnectionGuid = '00000000-0000-0000-0000-000000000001')\n",
    "        EXECUTE [integration].[sp_UpsertDataSource] \n",
    "            @ConnectionId = @ConnectionIdInternal\n",
    "            ,@DataSourceId = @DataSourceIdInternal\n",
    "            ,@Name = 'CUSTOM_NOTEBOOK'\n",
    "            ,@Namespace = 'NB'\n",
    "            ,@Type = 'NOTEBOOK'\n",
    "            ,@Description = 'Custom Notebook'\n",
    "            ,@IsActive = 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed267d7-4aca-445c-9189-243307a972e6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Add Workspaces to Fabric Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6f1cd-8aaa-4c94-be39-6721312e6cde",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#add all created workspace to database\n",
    "unique_items = {}\n",
    "for item in mapping_table:\n",
    "    if item.get(\"ItemType\") == \"Workspace\":\n",
    "        unique_items[item[\"new_id\"]] = item[\"Description\"]\n",
    "\n",
    "# Convert to list of tuples or dicts\n",
    "workspaces = [{\"Description\": desc, \"new_id\": nid} for nid, desc in unique_items.items()]\n",
    "\n",
    "for workspace in workspaces:\n",
    "    print(f'EXEC [integration].[sp_UpsertWorkspace](@WorkspaceId = \"{workspace[\"new_id\"]}\" ,@Name = \"{workspace[\"Description\"]}\")')\n",
    "    custom_sql_deployment[\"queries_stored_procedures\"].append(f'EXEC [integration].[sp_UpsertWorkspace] @WorkspaceId = \"{workspace[\"new_id\"]}\", @Name = \"{workspace[\"Description\"]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aacd228-4711-4836-a45d-0818ea6dc14e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Add Data Pipelines to Fabric Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8751f-ddad-47ed-9de2-1fbe2530d76f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for environment in environments:\n",
    "    result = run_fab_command(f\"api -X get workspaces/{environment['workspaces']['code']['id']}/items\", capture_output=True, silently_continue=True)\n",
    "    existing_items = json.loads(result)['text']\n",
    "    for item in existing_items.get('value', []):\n",
    "        if item['type'] == 'DataPipeline':\n",
    "            print(f'EXEC [integration].[sp_UpsertPipeline] @PipelineId = \"{item[\"id\"]}\", @WorkspaceId = \"{environment[\"workspaces\"][\"code\"][\"id\"]}\" ,@Name = \"{item[\"displayName\"]}\"')\n",
    "            custom_sql_deployment[\"queries_stored_procedures\"].append(f'EXEC [integration].[sp_UpsertPipeline] @PipelineId = \"{item[\"id\"]}\", @WorkspaceId = \"{environment[\"workspaces\"][\"data\"][\"id\"]}\" ,@Name = \"{item[\"displayName\"]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867745a-f0e7-4a9a-b326-5609b1b5bb3a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Add Lakehouses to Fabric Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc60a4a-1e3d-4a57-b2f7-2a8cb23115c6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for environment in environments:\n",
    "    result = run_fab_command(f\"api -X get workspaces/{environment['workspaces']['data']['id']}/items\", capture_output=True, silently_continue=True)\n",
    "    existing_items = json.loads(result)['text']\n",
    "    for item in existing_items.get('value', []):\n",
    "        if item['type'] == 'Lakehouse':\n",
    "            print(f'EXEC [integration].[sp_UpsertLakehouse] @LakehouseId = \"{item[\"id\"]}\", @WorkspaceId = \"{environment[\"workspaces\"][\"data\"][\"id\"]}\" ,@Name = \"{item[\"displayName\"]}\"')\n",
    "            custom_sql_deployment[\"queries_stored_procedures\"].append(f'EXEC [integration].[sp_UpsertLakehouse] @LakehouseId = \"{item[\"id\"]}\", @WorkspaceId = \"{environment[\"workspaces\"][\"data\"][\"id\"]}\" ,@Name = \"{item[\"displayName\"]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d60c485-1f24-4dbc-807b-45a71e14cf55",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Add Demo data for testing to Fabric Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a476a2-d34d-4540-ad24-439d447c5289",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "if load_demo_data:  \n",
    "    demo_sql_deployment = {\"queries_stored_procedures\": []}\n",
    "    demo_sql_deployment[\"queries_stored_procedures\"].append(\"\"\"\n",
    "        DECLARE @LandingzoneEntityIdInternal INT = (SELECT LandingzoneEntityId FROM integration.LandingzoneEntity WHERE SourceSchema = 'in' and SourceName = 'customer')\n",
    "        DECLARE @DataSourceIdInternal INT = (SELECT DataSourceId FROM integration.DataSource WHERE Name = 'LH_DATA_LANDINGZONE' and Type='ONELAKE_TABLES_01')\n",
    "        DECLARE @LakehouseIdInternal INT = (SELECT top 1 LakehouseId FROM integration.Lakehouse WHERE Name = 'LH_DATA_LANDINGZONE')\n",
    "        EXECUTE [integration].[sp_UpsertLandingzoneEntity] \n",
    "            @LandingzoneEntityId = @LandingzoneEntityIdInternal\n",
    "            ,@DataSourceId = @DataSourceIdInternal\n",
    "            ,@LakehouseId = @LakehouseIdInternal\n",
    "            ,@SourceSchema = 'in'\n",
    "            ,@SourceName = 'customer'\n",
    "            ,@SourceCustomSelect = ''\n",
    "            ,@FileName = 'customer'\n",
    "            ,@FilePath = 'fmd'\n",
    "            ,@FileType = 'parquet'\n",
    "            ,@IsIncremental = 0\n",
    "            ,@IsIncrementalColumn = ''\n",
    "            ,@IsActive = 1\n",
    "            ,@CustomNotebookName = ''\n",
    "    \"\"\")\n",
    "    demo_sql_deployment[\"queries_stored_procedures\"].append(\"\"\"\n",
    "        DECLARE @LandingzoneEntityIdInternal INT = (SELECT LandingzoneEntityId FROM integration.LandingzoneEntity WHERE SourceSchema = 'in' and SourceName = 'customer')\n",
    "        DECLARE @BronzeLayerEntityIdInternal INT = (SELECT BronzeLayerEntityId FROM integration.BronzeLayerEntity WHERE [Schema] = 'in' and [Name] = 'customer')\n",
    "        DECLARE @LakehouseIdInternal INT = (SELECT top 1 LakehouseId FROM integration.Lakehouse WHERE Name = 'LH_BRONZE_LAYER')\n",
    "        EXECUTE [integration].[sp_UpsertBronzeLayerEntity] \n",
    "            @BronzeLayerEntityId = @BronzeLayerEntityIdInternal\n",
    "            ,@LandingzoneEntityId = @LandingzoneEntityIdInternal\n",
    "            ,@Schema = 'in'\n",
    "            ,@Name = 'customer'\n",
    "            ,@FileType = 'Delta'\n",
    "            ,@LakehouseId = @LakehouseIdInternal\n",
    "            ,@PrimaryKeys = 'CustomerId'\n",
    "            ,@IsActive = 1\n",
    "    \"\"\")\n",
    "    demo_sql_deployment[\"queries_stored_procedures\"].append(\"\"\"\n",
    "        DECLARE @BronzeLayerEntityIdInternal INT = (SELECT BronzeLayerEntityId FROM integration.BronzeLayerEntity WHERE [Schema] = 'in' and [Name] = 'customer')\n",
    "        DECLARE @SilverLayerEntityIdInternal INT = (SELECT SilverLayerEntityId FROM integration.SilverLayerEntity WHERE [Schema] = 'in' and [Name] = 'customer')\n",
    "        DECLARE @LakehouseIdInternal INT = (SELECT top 1 LakehouseId FROM integration.Lakehouse WHERE Name = 'LH_SILVER_LAYER')\n",
    "        EXECUTE [integration].[sp_UpsertSilverLayerEntity] \n",
    "            @SilverLayerEntityId = @SilverLayerEntityIdInternal\n",
    "            ,@BronzeLayerEntityId = @BronzeLayerEntityIdInternal\n",
    "            ,@LakehouseId = @LakehouseIdInternal\n",
    "            ,@Name = 'customer'\n",
    "            ,@Schema = 'in'\n",
    "            ,@FileType = 'delta'\n",
    "            ,@IsActive = 1\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3bfba-b56e-47c7-a1e5-c764c2c3e622",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Deploy SQL Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7b58e-1240-4110-a4a1-c7c767bad1ee",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Make sure out token is still valid before we continou, sometime it can take a bit longer that's we will check it again\n",
    "token = notebookutils.credentials.getToken('pbi')\n",
    "os.environ['FAB_TOKEN'] = token\n",
    "os.environ['FAB_TOKEN_ONELAKE'] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6c1ec-7fac-46d6-812a-50c00e413c5e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for deployment_item in data_deployment:\n",
    "        if deployment_item['type'] in ('SQLDatabase'):\n",
    "                name = configuration['DatabaseName']\n",
    "                type = deployment_item[\"type\"]\n",
    "                name=name+'.'+type\n",
    "                if not server:         #it was already set, just in case\n",
    "                    server=get_item_id(configuration['workspace']['name'], name, 'properties.serverFqdn')\n",
    "                if not database_name:    \n",
    "                    database_name=get_item_id(configuration['workspace']['name'], name, 'properties.databaseName')\n",
    "\n",
    "try:\n",
    "    i = 0\n",
    "\n",
    "    token = notebookutils.credentials.getToken('pbi').encode('utf-16-le')\n",
    "    token_struct = struct.pack(f'<I{len(token)}s', len(token), token)\n",
    "\n",
    "    print(f\"DRIVER={driver};SERVER={server};PORT=1433;DATABASE={database_name};\")\n",
    "    connection = pyodbc.connect(f\"DRIVER={driver};SERVER={server};DATABASE={database_name};\", attrs_before={1256:token_struct}, timeout=12)\n",
    "\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"SELECT 1\")  # Execute the warm-up query (a simple query like 'SELECT 1' can be used)\n",
    "        cursor.fetchone()\n",
    "        connection.timeout = 10  # Setting a lower timeout for subsequent queries\n",
    "\n",
    "    for i, query in enumerate(custom_sql_deployment[\"queries_stored_procedures\"]):\n",
    "        print(f' - execute \"{query}\"')\n",
    "        cursor.execute(query)\n",
    "        cursor.commit()\n",
    "    for i, query in enumerate(demo_sql_deployment[\"queries_stored_procedures\"]):\n",
    "        print(f' - execute \"{query}\"')\n",
    "        cursor.execute(query)\n",
    "        cursor.commit()\n",
    "\n",
    "    tasks.append({\"task_name\":f\"{workspace.get('displayName')} {database_name} query {i}\", \"task_duration\": 1, \"status\": f\"success\"})\n",
    "except pyodbc.OperationalError as e:\n",
    "    print(e) \n",
    "    tasks.append({\"task_name\":f\"{workspace.get('displayName')} {database_name} query {i}\", \"task_duration\": 1, \"status\": f\"pyodbc failed: {e}\"})\n",
    "except Exception as e:\n",
    "    print(e) \n",
    "    tasks.append({\"task_name\":f\"{workspace.get('displayName')} {database_name} query {i}\", \"task_duration\": 1, \"status\": f\"failed: {e}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61b1ee-8f24-4760-b2a6-f207bb10eea4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "display(tasks)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {}
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "3600000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}